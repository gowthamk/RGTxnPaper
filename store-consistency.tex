\section{Data Stores and Consistency}
\label{sec:store-consistency}

The abstract machine
of Fig.~\ref{fig:txnimp} allows operations to witness arbitrary
subsets of the global state, thus assuming the semantics of an
eventually consistent ({\sc ec}) data store\footnote{{\sc ec}
guarantees that in the absence of further updates, all reads witness
the same global state \emph{eventually}. In any finite trace, however,
there are no guarantees on what a read witnesses.}. There are however
stores, such as relational databases, that provide stronger
consistency guarantees than {\sc ec}. Like the isolation levels of
transactions, the consistency level of the underlying store also
affects the semantics of a program in non-trivial ways. In this
section, we demonstrate how the semantics of stronger stores with
on-demand weak isolation can be captured in our operational model
and reasoning framework.

% A non-trivial $\I$ composed of isolation specifications from
% Fig.~\ref{fig:ansi-isolation} induces the machine to provide
% non-trivial isolation guarantees for transactions. However, weak
% isolation levels often only constrain the visibility sets of
% operations by dictating what \emph{not} to see; not what to see.  For
% instance, \iso{Repeatable Read} isolation prohibits operations of a
% transaction from witnessing different states. It, however, does not
% prohibit all operations of a transaction from witnessing an aribitrary
% subset of the global state. Consequently, the machine can remain an
% {\sc ec} store even while providing non-trivial isolation. How then to
% model the semantics of an {\sc sc} store, such as a relational
% database, with variable (weak) isolation?

Firstly, we observe that the semantics of stronger stores can be
captured by store-specific consistency constraints, along with
transaction-specific isolation constraints, via the trace invariant
$\I$. In particular, we split $\I$ into two components: (1).  $\I_s$,
the store-specific invariant, and (2). $\I_c$, the program-specific
(or, client-specific) invariant, to capture consistency and isolation
constraints, respectively. $\I$ is now a conjunction:
  $\I \;=\; \lambda\E.~\I_s(\E) \wedge \I_c(\E)$.
While the program-specific trace invariant ($\I_c$) and remains an
invariant regardless of the store, the store specific invariant
($\I_s$) changes from store to store depending on the consisteny
level. $\I_s$ for an {\sc ec} store is $true$. Stronger stores, such
as an {\sc sc} store, have non-trivial $\I_s$.

A strongly-consistent {\sc sc} store guarantees a total order of all
operations w.r.t $\visZ$ consistent with their chronological order. A
straightforward $\I_s$ for this store is the \C{SC} property
formalized below:
\begin{smathpar}
\begin{array}{l}
  \C{SC}(\E) \;=\; \forall\eta_1,\eta_2.~\{\eta_1,\eta_2\}
  \subseteq \E.\A \conj \id(\eta_1) < \id(\eta_2) \\
  \hspace*{2in}\Rightarrow \underE{\eta_1 \visar \eta_2}
\end{array}
\end{smathpar}
Unfortunately, $\I_s=\C{SC}$ conflicts with all isolation
specifications of Fig.~\ref{fig:ansi-isolation}. For instance,
consider a case where $\I_c(\E) \;=\; \forall
T_i.~\underE{\C{RC}(T_i)}$, a constraint that dictates all
transactions execute under \iso{Read Committed} isolation. Imagine a
sample execution where $\eta_1$'s transaction is not yet committed
when $\eta_2$ is generated. Letting $\eta_1$ be visible to $\eta_2$
violates $\I_c$, whereas not letting it be visible violates $\I_{s}$.
The only way to satisfy both the invariants is to rule out all the
executions that interleave the operations of one transaction with the
other, thereby enforcing serializability \footnote{Thus,
serializability is a natural generalization of {\sc sc} to
transactions.}. In general, when $\I_s$ is in conflict (but not
inconsistent) with $\I_c$, the only way to enforce both invariant sets
is to restrict concurrency. Clearly, this is unacceptable since it
defeats the very purpose of supporting weak isolation. 
% How then do we enforce weak isolation on a strongly consistent
% machine?

In practice, relational databases resolve the conflict by prioritizing
weak isolation (thus, concurrency and performance) over strong
consistency, so the execution traces do not necessarily satisfy {\sc
sc}. In particular, visibility constraints imposed by {\sc sc} are
violated if (and only if) they are found to be in conflict with the
constraints imposed by the isolation level. In the context of
aforementioned example, $\eta_1$ is not made visible to $\eta_2$
because doing so would violate $\I_c$. However, if $\I_c$ is true,
then the store makes $\eta_1$ visible to $\eta_2$ to honor its
consistency commitment\footnote{The term
\emph{recency}~\cite{bailisvldb} is often used in place of consistency
to capture the best-effort nature of the {\sc sc} guarantee on
databases.}. We generalize this approach to any $\I_s$ and $\I_c$ by
defining a \emph{maximum visiblity principle} to determine an
acceptable weakening of $\I_s$ in case of a conflict with $\I_c$.  The
principle requires the weakened consistency guarantee ($\I_s'$) of the
store to enforce all visibility relationships imposed by the actual
consistency guarantee ($\I_s$), unless enforcing such a relationship
violates $\I_c$. Formally:
\begin{definition}
$\I_s' : \E \rightarrow \Prop$ is said to be a maximum visibility
weakening of $\I_s : \E \rightarrow \Prop$ if and only if:
\begin{itemize}
  \item $\I_s'$ is weaker than $\I_s$: 
      $\forall\E.~ \I_s(\E) \Rightarrow \I_s'(\E)$, and
  \item In every trace $\E$ that satisfies $\I_c$, and for every pair
  of effects $\eta_1$ and $\eta_2$ in $\E$, if $\I_s(\E)$ requires
  $\eta_1$ to be visible to $\eta_2$, then so does $\I_s'(\E)$ unless
  extending $\E$ with $\visZ(\eta_1,\eta_2)$ violates
  $\I_c$\footnote{\GK{ToDo: consider other well-formedness conditions
  on trace, such as acyclicity of $\visZ$ and $\soZ$. Are they needed
  (considering that the machine never violates them)? Encode the
  specifications in Z3 and make sure they are consistent.}}:
  \begin{smathpar}
  \begin{array}{l}
  \forall\E,\eta_1,\eta_2.~ \I_c(\E) \Rightarrow (\I_s(\E)
    \Rightarrow \underE{\eta_1 \visar \eta_2}) \Rightarrow \\
    \hspace*{0.5in}(\I_s'(\E) \Rightarrow \underE{\eta_1 \visar
    \eta_2} \disj \neg\I_c(\E\,\cup\,(\emptyset,\{(\eta_1,\eta_2)\})))
  \end{array}
  \end{smathpar}
\end{itemize}
\end{definition}

Applying this principle, we can weaken {\sc sc} to obtain the
following store trace invariant ($\I_s$) for an {\sc sc} store whose
isolation constraints are captured by $\I_c$:
\begin{smathpar}
\begin{array}{lcl}
\I_s(\E) & = & \forall \eta_1,\eta_2.\, \{\eta_1,\eta_2\},
    \subseteq \E.\A \conj \id(\eta_1) <
    \id(\eta_2) \\
    & & \hspace*{0.5in} \Rightarrow 
      \underE{\eta_1 \visar \eta_2} \disj \neg\I_c(\E
    \cup (\emptyset,\{(\eta_1,\eta_2)\}))\\
\end{array}
\end{smathpar}
Instantiating the parameter $\I$  with $\I_s \wedge \I_c$ in
Fig.~\ref{fig:txnimp} results in an operational semantics that
describes a practical {\sc sc} store, such as a relational database.

Semantics of a causally consistent data
store~\cite{gotsmanpopl16,LBC16} can also be obtained: by defining
$\I_s$ to be the causal consistency ({\sc cc}) invariant that is
appropriately weakened to resolve conflicts with $\I_c$. Details are
relegated to the supplementary in the interest of space.

\begin{remark}
Note that the purpose of maximum visibility principle is to
rationalize the observed behaviour of databases in practice. In
particular, it is not intended to be a guiding principle to engineer
data stores, and need not be objectively better than similar
principles.
\end{remark}

% \paragraph{A CC store} A causally consistent data store~\cite{gotsmanpopl16,LBC16}
% allows operations to only witness a causally consistent snapshot of the
% global state. The store-specific invariant obtained by weakening the
% {\sc cc} guarantee to account for conflicts with $\I_c$ is shown
% below (the original {\sc cc} does not contain the $\neg\I_c(\dots)$
% disjuncts): 
% \begin{smathpar}
% \begin{array}{lccl}
% \C{CC}(\E) & \;=\; &  & \forall \eta_1,\eta_2.\, 
%       \E \Vdash \eta_1 \soar \eta_2 \Rightarrow  \underE{\eta_1 \visar
%       \eta_2} \\
%     & & & \hspace*{0.6in}\disj \neg\I_c(\E \cup 
%                 (\emptyset,\{(\eta_1,\eta_2)\}))\\
%     &   & \wedge & \forall\eta_1,\eta_2,\eta_3.\,\underE{\eta_1 \visar
%       \eta_2} \conj \underE{\eta_2 \visoar \eta_3} \\
%     &   & &\hspace*{0.3in} \Rightarrow \underE{\eta_1 \visar \eta_3}
%       \disj \neg\I_c(\E \cup (\emptyset,\{(\eta_1,\eta_2)\}))\\
% \end{array}
% \end{smathpar}

% \noindent Instantiating the parameter $\I$  with $\I_s \wedge \I_c$ in
% Fig.~\ref{fig:txnimp} results in an operational semantics that admits
% violation of causal consistency if and only if the violation is
% inevitable to enforce $\I_c$.

\subsection{Eventually Consistent Replication}

\begin{figure}
\centering
\subcaptionbox {
  Replica model
  \label{fig:ec-theirs}
} [
  0.4\columnwidth
] {
  \includegraphics[scale=0.7]{Figures/ec-theirs}
 
}
\hspace*{0.1in}
\subcaptionbox {
  Subset model
  \label{fig:ec-ours}
}{
  \includegraphics[scale=0.45]{Figures/ec-ours}
} \caption{In the replica model, operation $\op$ generates effect
$\eta$ at replica $R_1$, which is then merged to $R_2$. If the
\emph{store is {\sc cc}}, then $R_2$'s state at merge event is same or
larger than $R_1$'s state at generation event (the difference is
highlighted). In our subset model, $\op$ witnesses $S_1 \subseteq
\E.\A$ and generates $\eta$, which is immediately added to $\E.\A$. A
later operation may witness $S_2 \subseteq \E.\A$, and if the
\emph{operation is} {\sc cc} and $\eta \in S_2$, then it also
witnesses $S_1$ (i.e., $S_1 \subseteq S_2$). } 
% Moreover, Like $R_2 - R_1$, if all effects in $S_2 - S_1$ are
% concurrent with $\eta$, i.e., $\not\exists\eta'.~\eta' \in S_2 - S_1
% \conj % visZ(\eta,\eta')$, then any precondition $P$ that is valid
% when $\op$ executed is also valid when $\eta$ is witnessed because
% of the stability condition.
\label{fig:ec-theirs-vs-ours}
\end{figure}

In this section, we present an intuitive explanation of the soundness
result in context of eventually consistent replication. 
% In other words, we explain why our approach is a sound way of
% reasoning about transactions under eventually consistent replication
% despite our system model not including the standard artifacts
% associated with a replicated store. 


Existing approaches to reason about eventually consistent replication
necessarily involve reasoning in terms of \emph{replicas} of data. The
primary challenge in this setting is to ensure that the assumptions
made and guarantees enforced by an operation at one replica carry over
to other replicas that merge its effects, thus preserving the overall
integrity of the system. Reasoning frameworks, such
as~\cite{gotsmanpopl16}, address this challenge by imposing
restrictions on how various replica states differ, i.e., by
strengthening the consistency of the store. Our view of eventually
consistent replication however does not explicitly involve replicas.
Fig.~\ref{fig:ec-theirs-vs-ours} contrasts our model of EC replication
with the conventional replica-based model.  Under our model, the
notion of a replica is subsumed by the concept of visibility; a
replica is defined by the subset ($S$) of global state ($\E.\A$) that
an operation witnesses.  Constraints over replica states therefore
manifest as constraints over the visibility relation. For example,
instead of requiring the store to be causally consistent, an operation
can request to witness a causally consistent subset of the state; such
demands can be made via the trace invariant $\I$. For a precondition
($P$) of the operation to be useful, it has to be an assertion over
every causally consistent subset of the global state. Since any
replica that eventually executes the operation has to expose one such
subset ($S$), the precondition is guaranteed to hold regardless of the
replica. There is however one problem with this explanation; by
considering subsets of just one global state, it ignores the fact that
the global state (hence, the replica states) change during the
execution of the operation. Existing approaches account for this
change by distinguishing between \emph{effect generation} event at one
replica and \emph{effect merge} event at another replica, and
requiring that certain invariants be preserved between these two
events at different replicas. Our framework folds all of this into a
stability condition (\S\ref{sec:rely-guarantee}). Since any change to
the global state during the execution of the operation is an
interference, and $P$ is required to be stable with respect to any
such interference, it follows that $P$ is valid on every replica, thus
ensuring that assumptions made at the generation event are also valid
at the merge event.

\subsection{Example}

\GK{Here, I plan to include the full example that we dropped from
\S\ref{sec:motivation}.}
