\section{\txnimp: Syntax and Semantics}
\label{sec:opsem}

\label{sec:syntax}

\input{txnimp}

Fig.~\ref{fig:txnimp} shows the syntax and small-step semantics of
\txnimp, a core language that we use to formalize our intuitions about
reasoning under weak isolation. Variables ($x$), Integer and boolean
constants ($k$), records ($r$) of named constants, sets ($s$) of such
records, arithmetic and boolean expressions ($e_1 \odot e_2$), and
record expressions ($\{\bar{f}=\bar{e}\}$) constitute the syntactic
class of expressions ($e$). Commands ($c$) include $\cskip$,
conditional statements, \C{LET} constructs to bind names, \C{FOREACH}
loops, SQL statements, their sequential composition ($c_1;c_2$), and
transactions ($\ctxn{i}{\I}{c}$) and their parallel composition
($c_1\,||\,c_2$). Certain terms that only appear at run-time are also
present in $c$. These include a \C{TXN} block tagged with sets ($\stl$
and $\stg$) of records that assume special meaning in operational
semantics, and a \C{FOREACH} loop that keeps track of the set ($s_1$)
of items already iterated, and the set ($s_2$) of items yet to be
iterated. Note that even the surface-level \C{FOREACH} shown here is a
little different from the one used in previous sections; its
higher-order argument has two arguments, $y$ and $z$, which are
invoked (during the reduction) with the set of already-iterated items,
and the current item, respectively. This form of \C{FOREACH} lends
itself to inductive reasoning, facilitating inductive proofs
(Sec.~\ref{sec:reasoning}).

% also We let $T_i$ for $i \in \mathbb{N}$
% range over transaction identifiers. When it is evident we are
% referring to a transaction, we use the number $i$ instead of $T_i$ for
% identification (\eg in $\C{txn}\langle i \rangle$). Like variables,
% transaction identifiers are globally accessible. For notational
% convenience, we let $t$ range over both expressions and commands.

We define a small-step operational semantics for this language in
terms of an abstract machine that executes a command, and updates
either a transaction-local database ($\stl$), or the global database
($\stg$). Database ($\stg$) is a modeled as a set of records of a
pre-defined type, i.e., they all belong to a single table.
Generalization to multiple tables is straightforward. Records in
$\stg$ are uniquely identifiable through their $\idf$ field, which is
auto-generated and does not belong to the surface language, i.e.,
$\C{id}\notin f$. For a set $S$ of records, we define $\dom(S)$ as the
set of unique ids of all the records in $S$. Thus $|\dom(\stg)| =
|\stg|$. During its execution, a transaction may write to multiple
records in $\stg$. Atomicity dictates that such writes shouldn't be
available in $\stg$ until the transaction commits. We therefore
associate each transaction with a local database ($\stl$) that stores
\emph{only} the uncommitted records\footnote{While SQL's \C{UPDATE}
admits writes at the granularity of record fields, databases, in
reality, enforce record-level locking, allowing us to think of
``uncommitted writes'' as ``uncommitted records''. }. Uncommitted
records include deleted records, which are identified by a hidden
$\delf$ field set to \C{true}. When the transaction commits, its local
database is atomically \emph{flushed} to the global database,
committing the uncommitted records. The flush operation ($\gg$) is defined as
following:
\begin{smathpar}
\begin{array}{c}
\forall r.~ r \in (\stl\gg\stg) ~\Leftrightarrow~ 
  (r.\idf \notin \dom(\stl) \conj r \in \stg)
\disj (r \in \stl \conj \neg r.\delf) 
\end{array}
\end{smathpar}
Let $\stg' = \stl\gg\stg$. A record $r$ belongs to $\stg'$ iff it
belongs to $\stg$ and not been updated in $\stl$, i.e., $r.\idf \notin
\dom(\stl)$, or it belongs to $\stl$, i.e., it is either a new record,
or an updated version of an old record, but the updatation is not a
deletion ($\neg r.\delf$). Thus, flush defines the result of
atomically applying transaction's local writes to the global database.
Besides the commit, flush also helps a transaction read its own
writes. Intuitively, the result of a read operation inside a
transaction must be computed on the database resulting from flushing
the current local state ($\stl$) to the global state ($\stg$). The
abstract machine of Fig.~\ref{fig:txnimp}, however, doesn't let a
transaction read its own writes. This reduces verbosity and simplifies
semantics, without losing any generality; substituting $\stl\gg\stg$
for $\stg$ at select places in reduction rules recovers the real

Small-step semantics is stratified into a transaction-local reduction
relation, and a top-level reduction relation. Transaction-local
relation ($\stg \vdash (c,\stl) \stepsto (c',\stl')$) defines a
small-step reduction for a command inside a transaction, when the
database state is $\stg$; the command $c$ reduces to $c'$, while
updating the transaction-local database $\stl$ to $\stl'$. The
definition assumes a meta function $\eval$ that evaluates expressions
with no free variables to values. The reduction relation for SQL
statements is defined straightforwardly.  \C{INSERT} adds a new record
to $\stl$ after adding a unique identifier (more discussion on
uniqueness later). \C{DELETE} finds the records in $\stg$ that match
the search criteria defined by its boolean function argument, and adds
the records to $\stl$ after marking them for deletion. \C{SELECT}
bounds the name introduced by \C{LET} to the set of records from
$\stg$ that match the search criteria, and then executes the bound
command $c$. \C{UPDATE} uses its first function argument to compute
the updated version of the records that match the search criteria
defined by its second function argument. Updated records are added to
$\stl$. 

The reduction of \C{FOREACH} starts by first converting it to its
run-time form that also keeps track of the iterated items ($s_1$),
besides the yet-to-be-iterated items ($s_2$). Initially, $s_1$ is
empty. As the elements are iterated, they are removed from $s_2$ and
added to $s_1$ . Iteration involves invoking the higher-order function
with $s_1$ and the current element $x$ (note: $\uplus$ in $\{x\}
\uplus s_2$ denotes a disjoint union). The reduction ends when the
$s_2$ becomes empty. The reduction rules for conditionals, \C{LET}
binders, and sequences are straightforward, hence ommitted.

The top-level reduction relation


% Fundamental to our development is the notion of a trace invariant
% ($\I$). $\I$ is a function from traces ($\E$) to first-order logical
% formulas ($\Prop$) that define well-formedness
% constraints over traces.  The machine takes a step only if the
% resulting trace satisfies the constraints imposed by $\I$. This
% behaviour is captured by the auxiliary reduction rule
% \rulelabel{E-Aux} that factors out the trace extension aspect of the
% evaluation by abstracting away the operation-specific behaviour as a
% function that generates an appropriate effect. We let $\mathcal{F}$
% denote this function.  \rulelabel{E-Aux} uses $\mathcal{F}$ to
% generate a new effect and extend the trace ($\E = (\A,\visZ)$)
% \emph{only if} the well-formedness constraints imposed by $\I$ on $\E$
% (i.e., $\I(\E')$) are satisfied. Otherwise, it gets stuck. In an
% execution that runs to completion, every small-step preserves the
% well-formedness of a trace, thus ensuring the invariance of $\I$.
% Note that the semantics makes no assumptions about $\I$ other than its
% type. As such, it can be instantiated with any trace-parametric
% proposition that expresses constraints over the given trace. For
% instance, consider the $\psi_{RC}$ specification from
% \S\ref{sec:motivation}, but with bounded $T_1$ and $T_2$ instantiated
% with \C{Wd1} and \C{Wd2}, respectively. The instantiated specification
% is the following term:\vspace*{-8pt}

% \begin{smathpar}
% \begin{array}{l}
%   \forall \eta_1,\eta_2.\; \txn(\eta_1) = \C{Wd1}
%   \conj \txn(\eta_2) = \C{Wd2} \\
%   \hspace*{0.6in}\conj \C{Wd1} \neq \C{Wd2} \conj \eta_1 \hboar
%   \eta_2 \Rightarrow \C{Wd1} \hboar \eta_2 \\
% \end{array}
% \end{smathpar}

% \noindent It is easy to interpret the above specification in the
% context of a trace $\E$ that captures an execution of the program in
% Fig.~\ref{fig:motiv-eg-1}. Such a trace-parametric formula can be
% used to instantiate the trace invariant $\I$ in Fig.~\ref{fig:txnimp}.
% The resultant operational semantics describes an abstract machine that
% gets stuck if an operation of \C{Wd2} is executed in a state that
% incorporates some, but not all the effects (including the \C{COMMIT})
% of \C{Wd1}.
% % While the machine takes a step only if the constraints are
% % satisfied, it neither defines nor explicitly assumes an oracle to
% % check satisfaction.

% As described in \S\ref{sec:motivation}, the semantics of various
% isolation levels can be captured as constraints over the
% happens-before ($\hbZ$) relation. $\hbZ$ is however a derived relation
% in our model, composed of more fundamental \emph{session order}
% ($\soZ$) and \emph{visibility} ($\visZ$) relations. In particular,
% $\hbZ \,=\, (\soZ \cup \visZ)^{+}$. Unlike $\hbZ$, $\visZ$ (defined
% below) is not a transitive relation, and hence lets us capture
% finer-grained isolation properties than $\hbZ$, which we leverage in
% our development.  The session order relation captures the sequential
% order of operations within a transaction. In particular, it relates
% two effects, $\eta_1$ and $\eta_2$, such that $\txn(\eta_1) =
% \txn(\eta_2)$ and $\id(\eta_1) < \id(\eta_2)$.  The semantics assigns
% monotonically increasing identifiers to effects, as defined by the
% $\id(\eta) > \maxId(\A)$ condition of \rulelabel{E-Aux} ($\maxId(\A)$
% returns the maximum number identifying an effect in $\A$). Evaluation
% contexts ($\ectx_i$) for transaction-bound terms are defined so as to
% enforce a deterministic sequential order of execution within a
% transaction, leading to a deterministic total order among effect ids,
% which defines the session order relation. Visibility ($\visZ$) on the
% other hand relates effects across concurrent transactions.
% Intuitively, $\visZ$ relates $\eta_1$ to $\eta_2$ if and only if
% $\eta_1$ was \emph{visible} to the operation that generated $\eta_2$
% during its execution, thus effecting its return value
% ($\rval(\eta_2)$). For example, a read operation over \C{X} may pick
% the value ($\rval$) of the write effect with the highest id among its
% visible effects (this is made possible by appropriately defining
% $\interp{\cdot}$ in \rulelabel{E-Var}, as we show later). Thus, the
% value of a read depends on what write effects it can witness. An
% operation can only witness the effects of already concluded
% operations, which varies between executions due to the
% non-deterministic order of evaluating the parallel composition of
% transactions.

% A more notable source of non-determinism, however, is the
% \rulelabel{E-Aux} rule, which allows the machine to expose an
% arbitrary subset ($S$) of existing effects ($\A$) to the incoming
% operation. In other words, the machine is not obligated to reveal the
% effects of all previous operations to an incoming operation. This
% relaxation allows the abstract machine to model the semantics of
% weakly-consistent data stores. For instance, operations issued to an
% eventually consistent ({\sc ec}) replicated store could be dispatched
% to different replicas whose states may not be in any well-defined
% relationship. By allowing operations to witness arbitrary subsets of
% the global state, the semantics models the weak visibility properties
% of such stores; we elaborate on the implication of this style of
% definition in \S\ref{sec:store-consistency}.  Stronger visibility
% properties can be expressed by imposing well-formedness constraints
% over $\visZ$ via the trace invariant ($\I$). Since the abstract
% machine is obligated to satisfy $\I$ at every step of the execution,
% operations are guaranteed to experience the level of isolation
% specified by $\I$.  Thus, in executions that run to completion, the
% abstract machine models a store that provides the required levels of
% isolation.  Notably, the machine achieves this without defining an
% operational semantics for isolation levels, instead solely relying on
% their declarative characterization as trace well-formedness
% constraints to enforce isolation guarantees.
% \S\ref{sec:ansi-isolation} specifies various ANSI SQL isolation levels
% stated as trace well-formedness constraints.

% % TRACE RELATIONS
% % ---------------
% \input{trace-relations}

% % However, a machine that lets operations witness arbitrary subset of
% % the global state offers no isolation whatsoever. For example, it may
% % allow a read operation to witness writes of an uncommitted
% % transaction, violating RC isolation. Fortunately, our ability to
% % express an isolation semantics as constraints over happens-before
% % order through $\visZ$ and $\soZ$ relations, and the property of the
% % abstract machine to be parametric over the trace invariant ($\I$),
% % lets us solve this problem.
% % In particular, we continue to define isolation semantics as
% % constraints over $\visZ$ and $\soZ$, but confine their domain of
% % interpretation to the given trace so that they now become trace
% % well-formedness constraints. Well-formedness constraints can be
% % combined into a trace invariant ($\I$). 


% As described previously, \rulelabel{E-Aux} abstracts away the
% operation-specific behaviour of a machine step as a function ($\F$)
% that accepts a set ($S$) of effects chosen by the machine to make
% visible to the operation, interprets the operation w.r.t. $S$, and
% returns an appropriate effect that encodes its return value. Rules
% \rulelabel{E-Var}, \rulelabel{E-Asgn} and \rulelabel{E-Commit} define
% such functions for read, write and commit operations, respectively.
% The effect returned by the function in each case includes its
% transaction id ($T_i$) along with an arbitrarily chosen effect id
% ($j$) that is later verified to be unique in \rulelabel{E-Aux}. The
% $\rval$ for a write is the value being written, and for commit it is
% $\bot$. In case of a read, the value read depends on how the read
% operation chooses to interpret the given set ($S$) of visible effects.
% The interpretation may depend on application semantics. For example, a
% monotonically increasing counter application may choose to let a write
% with the largest value determine the value of a read. To accommodate
% multiple interpretations, the semantics is made parametric over an
% interpretation function ($\interp{\cdot}$) that accepts a set of
% effects and a variable name, and returns the value associated with the
% variable. A straightforward interpretation function that chooses the
% last write (i.e., write with largest id) is shown below:

% \begin{smathpar}
% \begin{array}{lcl}
%   \isMax(S,\eta) & \Leftrightarrow &  \forall (\eta'\in S).  
%   \kind(\eta') = \kind(\eta) \\
%   & & \hspace*{0.4in}\Rightarrow \eta' = \eta \disj \id(\eta') < \id(\eta)\\

% \interp{S}(X) & = & \C{if}\;(\exists (\eta \in S). \kind(\eta) = \C{WR}(X) 
%   \wedge \isMax(S,\eta)) \\
%   & & \C{then}\;\rval(\eta)\;\C{else}\;0\\
% \end{array}
% \end{smathpar}

% \noindent Rules \rulelabel{E-Top-Ctx} and \rulelabel{E-Txn-Ctx} define
% congruence properties for top-level terms and transaction-bound terms,
% respectively. The rules and evaluation contexts ($\ectx$ and
% $\ectx_i$) are defined such that only certain kinds of terms are
% allowed at the top-level and inside a transaction. In particular, a
% \txnimp program at the top-level can either be a transaction, or a
% parallel composition of transactions. A command inside a \C{txn} block
% can either be an assignment, or a sequential composition of
% assignments. 

% \input{ansi-isolation}

