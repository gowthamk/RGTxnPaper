\section{Related Work}
\label{sec:relatedwork}

\paragraph{Specifying weak isolation.}
Adya~\cite{adyaphd} specified several weak isolation levels in terms
of \emph{dependency graphs} between transactions, by defining the
kinds of dependency cycles that are forbidden in each case. The
operational nature of Adya's specifications make them suitable for
runtime monitoring and anamoly
detection~\cite{kemmevldb,feketesigmod08,pssi2011}, whereas the
declarative nature of our specifications make them suitable for
reasoning about program behaviour. Sivaramakrishnan \emph{et
  al.}~\cite{pldi15} specify isolation levels declaratively as trace
well-formedness conditions, but their specifications implicitly assume
a complete trace with only committed transactions, and is thus not
suitable to reason operationally about a program as it builds the
trace. Cerone \emph{et al.}~\cite{gotsmanconcur15} present a framework
to specify isolation levels with atomic visibility, but their
specifications are also for complete traces; Moreover, their
formulation implicitly assumes homogenity, i.e., they require all
transactions to execute using either {\sc si} or {\sc ser}, which is
often not the case in practice. While all the aforementioned
specification frameworks use the vocabulary introduced
in~\cite{burckhardt14} to specify replicated data types and different
forms of weak consistency, in contrast to this work, none of them come
with an associated reasoning framework that can use such
specifications productively towards verifying programs under weak
isolation.

\paragraph{Reasoning under weak isolation} In~\cite{feketessi}, Fekete
\emph{et al.} propose a theory to characterize non-serializable executions
that arise under {\sc si}. Fekete~\cite{fekete2005} also proposes an
algorithm that allocates either {\sc si} or {\sc ser} isolation levels
to transactions while guaranteeing the serializability of the
execution. In~\cite{gotsmanpodc16}, Cerone \emph{et al.} improve on Adya's
{\sc si} specification and use it to derive a static analysis that
determines the safety of substituting {\sc si} with a weaker variant
called \iso{Parallel Snapshot Isolation}~\cite{psi}. All of them focus
on establishing the equivalence of executions between a pair of
isolation levels, without taking application invariants into account.
Bernstein \emph{et al.}~\cite{bern2000} propose informal semantic conditions
to ensure the satisfaction of application invariants under weaker
isolation levels.  However, no formal proof system has been proposed.
Furthermore, all the aforementioned approaches are tailor-made for a
finite set of well-understood isolation levels (rooted
in~\cite{berenson}) under a pre-defined consistency model (usually
{\sc sc}). 

\paragraph{Reasoning under weak consistency} There have been several
recent proposals on reasoning techniques for programs executing under
weak consistency~\cite{bailisvldb, alvarocalm,
  gotsmanpopl16,redblueatc, redblueosdi, ecinec}. All of them assume a
system model that offers a choice between a \emph{coordination-free}
weak consistency level (\emph{e.g.}, {\sc ec}~\cite{redblueosdi,
  redblueatc, ecinec, alvarocalm, bailisvldb} or causal consistency
({\sc cc})~\cite{gotsmanpopl16}). In all these efforts, the key
technical issue involves proving that atomic and fully isolated
operations preserve application invariants when executed on these
consistency levels.  In contrast, we admit weakly isolated
transactions (sets of atomic operations), and our system model accepts
\emph{specifications} of consistency and isolation levels drawn from
an expressive logic.  In recent work~\cite{gotsmanpopl16},
\iso{Parallel Snapshot Isolation} is adapted to the aforementioned
setting by interpreting it as a consistency level that serializes
writes to objects; a dedicated proof rule is developed to help prove
prove program invariants hold under this model. By parameterizing our
proof system over a gamut of weak isolation specifications, we avoid
the need to define a separate proof rule for each new isolation level.

\paragraph{Reasoning under relaxed memory} Considering the
correspondences between axiomatic models of relaxed
memory~\cite{battycpp} and weakly consistent
replication~\cite{burckhardt14}, it is reasonable to expect similar
reasoning approaches to work in both the cases. Ridge~\cite{rgtso}
generalizes rely-guarantee reasoning to the x86-TSO memory model.
Likewise, Vafeadis \emph{et al.}~\cite{rsl13} generalize concurrent
separation logic (CSL)~\cite{csl} to the C11 relaxed memory model.
Ferreira \emph{et al.}~\cite{ferreira10} propose a parameterized
operational semantics for relaxed memory models, but the
parameterization is over a relation between relaxed memory programs
and related {\sc sc} programs. They also prove the soundness of CSL
for the weakest memory model expressible in their semantics, but
neither a parameterized (in the aforementioned sense) CSL, nor a CSL
specialized for any relaxed memory model is proposed.  ~\cite{DLZ+13}
presents a \emph{buffered memory model} for Java that defines an
axiomatic definition for the JMM in terms of memory reorderings, and
an operational instantiation consistent with the TSO memory model
found on x86 processors, and demonstrates the equivalence of the two
definitions.  However, there is no attempt to parameterize the model
over different reordering or consistency definitions, which is a central
focus of this paper.

