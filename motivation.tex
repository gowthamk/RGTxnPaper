\section{Motivation}
\label{sec:motivation}

We have developed and implemented our ideas in an OCaml embedded DSL
that supports a \C{DB} monad to define and compose database
computations given in terms of SQL operations; the monadic \C{do}
syntax is borrowed from Haskell.  Besides the usual \C{bind} and
\C{return} combinators, monad offers an \C{atomically} combinator that
executes a database computation as an atomic transaction and returns
the result.

\begin{figure}
\centering
\begin{ocaml}
let new_order_ d_id c_id item_reqs = atomically do
  dist <- SQL.select1 District (fun d -> d.d_id = d_id);
  let o_id = dist.d_next_o_id;
  SQL.update District (fun d -> {d with d_next_o_id =d_next_o_id + 1})
                      (fun d -> d.d_id = d_id );
  SQL.insert Order {o_id=o_id;  o_d_id=d_id; 
                    o_c_id=c_id; o_ol_cnt=S.size item_reqs; };
  foreach item_reqs @@ fun item_req -> do
    stk <- SQL.select1 Stock (fun s -> s.s_i_id = item_req.ol_i_id);
    let s_qty' = if stk.s_qty >= item_req.ol_qty + 10 
                then stk.s_qty - item_req.ol_qty 
                else stk.s_qty - item_req.ol_qty + 91;
    SQL.update Stock (fun s -> {s with s_qty = s_qty'}) 
                     (fun s -> s.s_i_id = item_req.ol_i_id);
    SQL.insert Order_line {ol_o_id=o_id; ol_d_id=d_id; 
                           ol_i_id=item_req.ol_i_id; ol_qty=item_req.ol_qty}
 
\end{ocaml}
\caption{\small Concurrent withdraw transactions}
\label{fig:new_order_code}
\vspace*{-10pt}
\end{figure}

Fig.~\ref{fig:new_order_code} shows a simplified version of the TPC-C
\C{new\_order} transaction.  TPC-C is a well-known Online Transaction
Processing (OLTP) benchmark that models an order-processing system for
a wholesale parts supply business. The business logic is captured in 5
database transactions that operate on 9 tables. \C{new\_order} is one
such transaction that operates on \C{District}, \C{Order},
\C{New\_order}, \C{Stock}, and \C{Order\_line} tables. The transaction
acts on the behalf of a customer, whose id is \C{c\_id}, to place a
new order for the given set of items (\C{item\_reqs}), to be served by
a warehouse under the district identified by \C{d\_id}. The
transaction does so by invoking appropriate SQL functionality,
captured by various calls to functions under the \C{SQL} module. All
\C{SQL} functions take the table name (a nullary constructor) as their
first argument. The higher-order \C{SQL.select1} function accepts a
boolean function that describes the selection criteria, and returns
any record that meets the criteria (it models the SQL query \C{SELECT
  \ldots\xspace LIMIT 1}). \C{SQL.update} also accepts a Boolean
function (3rd argument) to select the records to be updated. Its
2$^{nd}$ argument is a function that maps each selected record to a new
(updated) record. \C{SQL.insert} inserts a given record into the
specified table in the database.

The \C{new\_order} transaction inserts a new \C{Order} record, whose
id is the sequence number of the next order under the given district
(\C{d\_id}). The sequence number is stored in the corresponding
\C{District} record, and updated each time a new order is added to the
system. Since each order may request multiple items (\C{item\_reqs}),
an \C{Order\_line} record is created for each requested item to relate
the order with the item. Each item has a corresponding record in the
\C{Stock} table, which keeps track of the quantity of the item left in
stock (\C{s\_qty}). The quantity is updated by the transaction to
reflect the processing of new order (if the stock quantity falls below
10, it is automatically replenished by 91).

TPC-C defines multiple invariants, called \emph{consistency
  conditions}, over the state of the application in the database. One
such consistency condition is the requirement that for a given order
\C{o}, the \emph{order-line-count} field (\C{o.o\_ol\_cnt}) should
reflect the number of order lines under the order, i.e., the number of
\C{Order\_line} records whose \C{ol\_o\_id} is equal to \C{o.o\_id}.
In a sequential execution, it is easy to see how this condition is
preserved.  A new \C{Order} record is added with its \C{o\_id}
distinct from the existing order ids, and its \C{o\_ol\_cnt} is set to
be equal to the size of \C{item\_reqs} set. The \C{foreach} loop runs
once for each \C{item\_req}, adding a new \C{Order\_line} record for
each requested item, with its \C{ol\_o\_id} field set to
\C{o\_id}. Thus, at the end of the loop, the number of \C{Order\_line}
records in the database, whose \C{ol\_o\_id} is equal to \C{o\_id}, is
equal to the size of the \C{item\_req} set, which in turn is equal to
the \C{Order} record's \C{o\_ol\_cnt} field, thus preserving the
consistency condition.

Because the aforementioned reasoning is reasonably simple to perform
manually, verfiying that soundess of TPC-C's consistency conditions
would appear to be feasible.  Serializability aids the tractability of
verification by preventing any interference among concurrently
executing transactions.  Under weak isolation\footnote{Weak isolation
  doesn't violate atomicity as long as the witnessed effects are those
  of committed transactions}, however, interferences of various kinds
are permitted.  Although the verification problem for weakly isolated
transactions would appear to be superficially similar to the
verification of (racy) concurrent programs~\cite{concurrentGC...},
weak isolation introduces new challenges arising from the use of
transactions, and new opportunities arising from the fact that the
store abstraction used by transaction is a relational database, not
low-level memory.  Our proof framework addresses these challenges and
exploits these opportunities to facilitiate fully automated
correctness proofs.

To illustrate, consider the behavior of the \C{new\_order} transaction
when executed with a \emph{Read Committed} (RC) isolation level, the
default isolation level in PostgreSQL, a widely used open-source
database system.  An RC transaction is isolated from \emph{dirty
  writes}, i.e., writes of uncommitted transactions, but is allowed to
witness the writes of concurrent transactions as soon as they are
committed. Thus, with two concurrent instances of the \C{new\_order}
transaction (call them $T_1$ and $T_2$), both concurrently placing new
orders for different customers under the same district (\C{d\_id}),
PostgreSQL admits the two executions shown in
Fig.~\ref{fig:new_order_execs}.

\begin{figure}[!h]
\centering
\subcaptionbox {
  {\sc rc} Execution 1
  \label{fig:motiv-eg-1-a}
} [
  0.55\columnwidth
] {
  \includegraphics[scale=0.6]{Figures/motiv-eg-1-a}
}
%\hspace*{0.5in}
\subcaptionbox {
  {\sc rc} Execution 2
  \label{fig:motiv-eg-1-b}
}{
  \includegraphics[scale=0.6]{Figures/motiv-eg-1-b}
}
\caption{\small A possible execution of the program shown in Fig.~\ref{fig:motiv-eg-1} under
  \iso{Read Committed} isolation level. Transaction \C{Wd1} is shown
  against lighter green background, and transaction \C{Wd2} against
  darker red background. Each transaction reads the balance (\C{B})
  twice, hence two \C{Reads}.}
\label{fig:rc-ex}
\end{figure}

The figure depicts an execution as a series of read, write, and commit
operations. In the execution on the left, the \C{new\_order} instance
$T_1$ (green) reads the \C{d\_next\_o\_id} field of the district
record for \C{d\_id}, but before it increments the field, another
\C{new\_order} instance ($T_2$) begins its execution and commits. Note
that $T_2$ reads the same \C{d\_next\_o\_id} value as $T_1$, and
inserts new \C{Order} and \C{Order\_line} records with their \C{o\_id}
and \C{ol\_o\_id} fields (resp.) equal to \C{d\_next\_o\_id}. $T_2$
also increments the \C{d\_next\_o\_id} field, which $T_1$ has already
acccessed. This is allowed because reads do not obtain a mutually
exclusive lock on most databases, including PostgreSQL. After $T_2$'s
commit, $T_1$ resumes execution and adds new \C{Order} and
\C{Order\_line} fields with the same order id as $T_1$. Thus, by the
end of the execution, \C{Order\_line} records inserted by $T_1$ and
$T_2$ all bear the same order id. There are also two \C{Order} records
with the same district id (\C{d\_id}) and order id, none of whose
\C{o\_ol\_cnt} reflects the actual number of \C{Order\_line} records
inserted with that order id.  This clearly violates TPC-C's consistency
condition.

Notably, this example does not exhibit any common concurrency bugs
that arise from incorrect use of weak isolation such as
\emph{write-write} conflicts, or \emph{lost updates}.  While $T_1$ and
$T_2$ both increment the \C{d\_next\_o\_id} field of the district
record, they do so atomically (Line 4 of
Fig.~\ref{fig:new_order_code}), allowing both updates to be present in
the final state. Likewise, other well-known anomalies that
characterize RC isolation~\cite{berenson} such as \emph{fuzzy reads},
\emph{phantom reads}, \emph{read skew}, and \emph{write skew}, are
also not exhibited by the example.  Thus, program analyses that aim to
determine appropriate isolation by checking for possible
manifestations of these anomalies would fail to identify grounds for
promoting the isolation level of \C{new\_order} to something stronger.
Yet, if we take the semantics of the application into account, it is
quite clear that RC is not an appropriate isolation level for
\C{new\_order}.

While reasoning in terms of anomalies is cumbersome, and as the above
example shows often inadequate, reasoning about weak isolation in
terms of low-level traces~\cite{adyaphd,gotsmanconcur15} confounds
high-level reasoning and automation.  Another alternative would
interleave weak isolation implementation details within the program,
yielding a (more-or-less) conventional concurrent program that can be
then subject to classical concurrent verification methods.
Considering the size and complexity of real-world transaction systems,
this approach is unlikely to scale.

In this paper, we adopt a different approach that \emph{lifts}
isolation semantics (\emph{not} their implementations) to the
application layer, providing a unified framework to simultaneously
reason about application invariants and isolation properties.  To
illustrate this idea informally, consider how we might verify that
\C{new_order} is sound when executed under a \emph{Repeatable Read}
(RR) isolation level.  PostgreSQL executes an RR transaction by taking
a (conceptual) snapshot of the database state before the transaction
begins that is used by reads performing the transaction.  When the
transaction attempts to update a record, a check is made to determine
if the current version of the record in the database is same as the
snapshot version. If it is, an exclusive lock is obtained on the
record, and the update is performed. If the record is already locked,
the transaction blocks until the lock is released.  When the lock is
obtained, is held exclusively until the transaction commits or rolls
back. If the aforementioned version check fails (i.e., the database
has a later version than the snapshot), the transaction is rolled back
and re-executed.

Although this implementation, comprising many thousands of lines code,
is highly involved, its semantic behavior in terms of how it effects
transitions on the database state is fairly simple.  Since a
transaction's reads are always served from a snapshot, no state
changes are witnessed while the execution is in progress. Thus,
insofar as an RR transaction is concerned, the database state does not
change during the execution.  Uncommitted writes are recorded in a
transaction-local state.  When the transaction commits, the local
state is atomically written to the global state to yield a global
state that reflects the transaction's updates.  However, unlike a
strongly isolated serializable transaction, the commit operation is
performed against the current state of the database, not the
snapshot. Thus, after the transaction finishes execution, but before
it commits, the transaction is able to witness the effects of all
concurrent transactions.  The PostgreSQL RR implementation effectively
constrains this transition.

We can axiomatize this operational description by observing that (a)
due to the version check, the current transaction cannot update a data
item that was already updated by a concurrent transaction, and (b) due
to the use of exclusive write locks, a data item updated by the
current transaction cannot be overwritten by a concurrent transaction.
If $\Delta$ is the state of the database when an RR transactions
finishes, and $\Delta_c$ is the state visible to the transaction at
the point of commit, we know the transition from $\Delta$ to
$\Delta_c$ (written $\Delta \longrightarrow \Delta_c$) cannot exhibit
effects from any concurrent transactions that write to the same data
items as the current RR transaction.  Similarly, if $\delta$ denotes
a local log that relates transaction variables being written with their updated values,
then $\forall x\in\mathit{dom}(\delta)$, $\Delta_c(x) =
\Delta(x)$. To summarize, the operational semantics of PostgresSQL's RR
implementation can be captured as an axiomatization over transitions of
the database state ($\Delta \longrightarrow \Delta'$) during the
lifetime an RR transaction ($T$):
\begin{itemize}
  \item While $T$ executes, $\Delta' = \Delta$.
  \item After $T$ finishes execution, but before it commits its local
    state $\delta$, $\forall(x\in\delta).~\Delta'(x) = \Delta(x)$.
\end{itemize}

This simple characterization of RR isolation allows us to verify the
consistency condtions associated with the \C{new\_order}
transaction. First, since the database doesn't change ($\Delta' =
\Delta$) (where $\Delta'$ represents the state after the transaction
commits), during the execution of the transaction's body, we can
reason about \C{new\_order} as if it executed in complete isolation
until its commit point, leading to a verification process similar to
what would been applied when reasoning about serializability.  When
\C{new\_order} finishes execution and becomes ready to commit, a
transition that transfers the transaction'slocal writes ($\delta$) to
the unchanged database state ($\Delta$).  However, we are required to
consider the interference from concurrent transitions at this point,
which might change the database state from $\Delta$ to $\Delta_c$. If
this interference includes the effects of a concurrent \C{new\_order}
transaction (with the same \C{d\_id}), then verification fails as
described previously (Fig.~\ref{fig:new_order_execs}). Fortunately,
sequential reasoning shows that this is impossible - RR prevents a
concurrent \C{new\_order} transaction that modifies the same
\C{District} record as the current transaction (concretely, since the
record is already present in the current transaction's local log, any
transition from $\Delta$ to $\Delta_c$ cannot change this record).
Applying such axiomatic reasoning on \C{new\_order} allows us to prove
that the TPC-C invariant holds when the transaction is executed under
PostgreSQL's RR isolation.  Our proof framework generalizes this style
of reasoning to various isolation levels on databases.

The second observation that informs our approach is one that pertains
to automation. Program verification, even when machine-aided, often
entails significant annotation burden in the form of intermediary
assertions and loop invariants required to prove a program correct.
This is certainly true for concurrent program logics, such as
Rely-Gurantee, which extend Hoare logic with additional artifacts and
where (stable) intermediary assertions and loop invariants remain a
major source of annotation burden.  Since database transactions
inherently deal with mutable state, it is natural to formulate them as
concurrent imperative programs.  An advantage with this formulation is
that it lets us immediately apply existing concurrent program logics
to database transactions, albeit with necessary customizations to deal
with weak isolation. The significant downside is that complicates
automation given the need to infer stable assertions and invariants.

However, a relational database is a significantly simpler abstraction
than shared memory. There are no pointers, or linked data structures,
or aliasing. While a database essentially abstracts a mutable state,
the state is mutated in through a finite number of interfaces (SQL
statements) in a well-defined way (e.g., SQL UPDATE and DELETE
statements are tagged with a logical formula describing what records
are updated). Thus, database programs enforce structure on operations
and the objects they manipulate.  This structure is key to realizing
automated verification.


--------------------------------------------
However, In the light of aforementioned reservations, we refrain from
formulating database transactions as concurrent imperative programs.
Instead, we see value in viewing them as essentially functional
programs that manage the database state via a monad akin to the
\C{State} monad~\cite{statemonad}. We find it useful to reason about
statements that mutate the database state, not in terms of a pre- and
post-condition pair, but in terms of a state transformer that relates
the pre- and post-states of a statement. Loops are substituted with
higher-order combinators that have a well-defined control flow, and
facilitate well-founded recursion. The static semantics of these
combinators let us lift the state transformer of its higher-order
argument (i.e., the loop body) to the state transformer of the
combined expression (i.e., the loop). This is made possible due to the
characteristic structure of database programs, which also gets
reflected in the structure of the state transformer. We illustrate
this point through a simple example that doesn't involve transactions,
but is nonetheless relevant.

% \begin{figure}[!t]
% \centering
% %
% \begin{subfigure}[b]{0.46\textwidth}
% \begin{ocaml}
% Set s' = $\emptyset$;
% foreach x in s {
%   s'.add(f(x)); 
% }
% \end{ocaml}
% \caption{}
% \end{subfigure}
% %
% \begin{subfigure}[b]{0.5\textwidth}
% \begin{ocaml}
% let s' = ref [];
% foreach s (fun x -> s' := x::(!s'));
% \end{ocaml}
% \caption{Lorem ipsum, lorem ipsum,Lorem ipsum, lorem ipsum,Lorem ipsum}
% \end{subfigure}
% \caption{Caption place holder}
% %
% \caption{New versions are created from existing versions either
% through \C{push} or \C{merge}.}
% \label{fig:syntactic-ancestors}
% \end{figure}
\begin{figure}[!h]
\begin{ocaml}
let l' = ref [];
foreach l (fun x -> l' := x::(!l'));
\end{ocaml}
\caption{A program that uses mutable state to reverse a list of elements}
\label{fig:mutable-rev}
\end{figure}

Consider the program in Fig.~\ref{fig:mutable-rev} that populates a
mutable list (\C{l'}) with elements from other list (\C{l}), reversing
their order. The aim is to show that, when the program ends, both
\C{l'} and \C{l} contain the same set of elements. If we were to
attempt Hoare-style verification, we are obligated to define an
inductive invariant for the \C{foreach} loop. Unfortunately, none
exists for the loop, as such. The reason is that there is no way in
the program to refer to the elements in the list that have already
been added to the list \C{l'}. This problem can be easily rectified by
introducing an integer \C{i} that keeps track of the index of \C{x} in
\C{l}. 

<<<<<<< HEAD
%% We have thus far assumed a strongly consistent ({\sc sc}) store that,
%% in the absence of transactions with special isolation requirements,
%% makes the effects of any operation immediately visible to all
%% subsequent operations. The natural behaviour of {\sc sc} to totally
%% order all operations w.r.t. the $\hbZ$ relation could be in conflict
%% with the constraints imposed by weak isolation. To meet the
%% requirements of weaker isolation levels, say {\sc rc}, the store has
%% to adapt itself to \emph{hide} the effects of concurrent transactions
%% until they are committed. Once committed though, effects need to be
%% immediately visible to subsequent operations. This semantics can be
%% built into the reasoning framework, leading to a proof system
%% tailor-made for such stores. However, for the reasoning framework to
%% be truly useful, it has to be parametric over different consistency
%% semantics, supporting stores that are weaker than {\sc sc} (e.g.,
%% causally or eventually consistent), and should be able to reconcile
%% conflicts between consistency and isolation constraints.  We
%% demonstrate how our reasoning framework makes this possible in the
%% following sections.


For example, \emph{Repeatable
  Read} is a stronger isolation level that RC; we might ask whether
executing the \C{new_order} transaction under this isolation level
would preserve the consistency conditions of the transaction.  To
answer this question, we must relate the low-level specification of RR
given in terms of e.g., trace-based
relations~\cite{adyaphd,gotsmanconcur15} to the semantics of TPC-C,
which is difficult.   Alternatively, one could reason about how RR is
implemented, say on PostgresSQL, and reason about the \C{new\_order}
implementation in conjunction with Postgres's RR
implementation. However, this is not any easier, considering that
Postgres employs a host of techniques, including Multiversion, locks
and rollbacks, to implement RR. The verification problem becomes even
more difficult if the aim is to facilitate automation. Our experience
suggests that a proof framework that requires programmers to relate
trace-based isolation specifications to program semantics necessarily
imposes heavy annotation burden, requires painstakingly long and
verbose proofs, and does not lend itself to automation. Weak isolation
aside, there are also the conventional challenges that face
(automatic) verification of concurrent programs: facilitating modular
proofs, inferring intermediary assertions and loop invariants that are
stable w.r.t interference, etc. A proof system for weakly isolated
transactions has to necessarily address these challenges, along with
those that arise due to weak isolation.
=======
>>>>>>> e392b4f8e54a903398fa34703952e2e919268d5b
