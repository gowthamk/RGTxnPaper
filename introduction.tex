\section{Introduction}

Database transactions allow users to group operations on multiple
objects into a coherent unit with useful properties including
atomicity, consistency, (serializable) isolation and durability
(ACID). ACID has been the gold standard for database transactions for
many decades, providing programmers with a simple
implementation-independent model to reason about concurrent
transactions. However, serializability, the ACID-prescribed standard for
isolation, does not come for free; it requires databases to rely on
expensive techniques such as two-phase locking~\cite{twopl,ullmanbook}
that severely restrict concurrency while incurring an additional
overhead of deadlock detection, rollback and re-execution. Enforcing
serializability in a replicated data store requires global
coordination among geo-distributed replicas, which makes the store
\emph{unavailable} in presence of the inevitable network
partitions~\cite{cap,sernotavlbl,bailishat,bernsigmod13}. The
conflict between serializability and pragmatic goals of high
peformance and availability has motivated the development of multiple
weaker forms of transaction isolation beginning as early as
1976~\cite{gray1976}. ANSI SQL 92 standard defines three such weak
isolation \emph{levels} which are now implemented in
many relational and NoSQL databases. Weakly isolated transactions have
been found to significantly outperform serializable transactions on
benchmark suites, both on single-node databases and multi-node
replicated stores~\cite{dbtuningbook,bailishat,bailisvldb}, leading to
their overwhelming adoption. A 2013 study~\cite{bailishotos} of 18
popular ACID and ``NewSQL'' databases found that only 3 of them offer
serializability by default, and half, including Oracle 11g, do not
offer it at all.  A 2015 study~\cite{bailisferal} of a large corpus of
database applications finds no evidence of any of them changing the
default isolation level offered by the database. Together, the studies
establish the prevalance of weak isolation in practice.

Unfortunately, weak isolation introduces new set of behaviors into
programs that often give rise to anomalous executions and
incomprehensible results~\cite{pldi15}. To quantify weak isolation
anomalies, Fekete et al~\cite{feketevldb09} have devised and
experimented with a microbenchmark suite that executes transactions
under \iso{Read Committed} isolation level - the default level for 8
of the 18 databases studied in~\cite{bailishotos}, and found that 25
out of every 1000 rows in the database violate at least one integrity
constraint. Bailis et al~\cite{bailisferal} rely on Rails's
\emph{uniqueness validation} to maintain uniqueness of records while
serving Linkbench's~\cite{linkbench} insertion workload (6400 records
distributed over 1000 keys; 64 concurrent clients), and end up with
more than 10 duplicate records. Rails relies on database transactions
to validate uniqueness during insertions, which is ok if transactions
are serializable, but incorrect under \iso{Read Committed} isolation
used in the experiments. The same study has found that 13\% of all
invariants among 67 open source Ruby-on-Rails applications are the
risk of being violated due to weak isolation. Indeed, incidents of
safety violations due to weak isolation have been reported on web
services in production~\cite{starbucksbug, scimedbug}, including in
safety-critical applications such as bitcoin
exchanges~\cite{poloniexbug, bitcoinbug}. Evidently, the ill effects
of weak isolation are as prevalent as the weak isolation itself.

The root cause of problems with weak isolation is that its semantics
in context of user programs is not well-understood. The original
proposal~\cite{gray1976} defines multiple ``degrees'' of weak
isolation in terms of implementation details, such as the nature and
duration of locks held in each case. ANSI SQL 92 standard four levels
of isolation (including serializability) in terms of sevaral
undesirable \emph{phenomena} (\eg \emph{dirty reads}) each is required
to prevent. While this is an improvement, it requires programmers to
be clairvoyant about the possible ways various undesirable phenomena
might manifest in their applications, and determine, in each case, if
the phenomenon can be allowed without violating application
invaraints. Adya's thesis~\cite{adyaphd} includes first formal
definitions of some of the well-known isolation levels in the context
of a sequentially consistent (SC) database. However, there have been
no attempts to relate Adya's system model to an operational model of
programs in a reasoning framework that facilitates formal proofs of
correctness. For this reason, the unsystematic way of reasoning about
weak isolation in terms of undesirable phenomena remains popular to
date, with major database vendors continuing to document their
isolation levels in terms of the such phenomena~\cite{postgresiso,
mysqliso, oracleiso}.

There have been encouraging developments in Programming Languages and
Systems research towards reasoning about application invariants in
presence of weak consistency~\cite{burckhardt14, redblueosdi,
redblueatc, ecinec, gotsmanpopl16}. Weak isolation can make use of
some of the reasoning inventory built for weak consistency (as we
demonstrate in later sections), but the former problem is strictly
more general than the latter. At a high level, reasoning about weak
consistency involves reasoning about concurrent execution of atomic
and fully isolated operations against different but consistent states
of the database, where each operation locally preserves invariants. In
contrast, reasoning about weak isolation involves reasoning about
concurrent execution of transactions, whose operations witness
different states which, although consistent individually, may not be
reconciled into a consistent view. Moreover, operations may violate
invariants as long as the transaction as a whole preserves them. It is
easy to see that the latter problem reduces to the former if all
transactions are singletons. The generality of weak isolation is also
evident from the fact that weakly isolated transactions have existed
on sequentially consistent relational databases long before the advent
of weakly consistent replicated stores. Thus, there is a need for
reasoning frameworks for weak isolation that generalize those for weak
consistency in some important ways. The framework should be general
enough to reason about the semantics of various isolation levels,
including ANSI SQL isolation levels, in the context of data stores
with various consistency semantics (\eg sequentially consistent data
store of~\cite{adyaphd}, causally consistent store assumed
in~\cite{gotsmanpopl16} etc). Considering the increasing diversity in
the semantics of weak consistency~\cite{zoo} and
isolation~\cite{gotsmanconcur}, it is ideal if the reasoning framework
is parameterized on the semantics of consistency and isolation.  In
short, what is neededis a reasoning framework that can answer the
following question:
\begin{center}
\emph{Given a program annotated with desired invaraints, and isolation
semantics for transactions in the program, assuming that the program
executes against a data store with a given consistency semantics, are
the invariants guaranteed to hold?}
\end{center}

In this paper, we propose a reasoning framework that attempts to
answer this question.

